{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## import modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "source": [
    "## training data in our test example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Green', 3, 'Apple'], ['Yellow', 3, 'Apple'], ['Red', 1, 'Grape'], ['Red', 1, 'Grape'], ['Yellow', 3, 'Lemon']]\n"
     ]
    }
   ],
   "source": [
    "training_data=[\n",
    "    ['Green',3,'Apple'],\n",
    "    ['Yellow',3,'Apple'],\n",
    "    ['Red',1,'Grape'],\n",
    "    ['Red',1,'Grape'],\n",
    "    ['Yellow',3,'Lemon'],\n",
    "]\n",
    "print(training_data)"
   ]
  },
  {
   "source": [
    "transform categorical data into integers:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 2 1 1 2]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0, 3, 0], [2, 3, 0], [1, 1, 1], [1, 1, 1], [2, 3, 2]]"
      ]
     },
     "metadata": {},
     "execution_count": 318
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "x_color= [ x[0] for x in training_data]\n",
    "x_label= [ x[2] for x in training_data]\n",
    "y_color = label_encoder.fit_transform(x_color)\n",
    "y_label = label_encoder.fit_transform(x_label)\n",
    "print(y_color)\n",
    "data_set=[ [col1,col2[1],col3] for (col1,col2,col3) in zip(y_color,training_data,y_label)]\n",
    "# data_set = np.array(test)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(training_data):\n",
    "    n_features = len(training_data[0])\n",
    "    data_set = []\n",
    "    for col in range(n_features):\n",
    "        x = [ data[col] for data in training_data ]\n",
    "        if isinstance(training_data[0][col],int):\n",
    "            data_set.append(x)\n",
    "            continue\n",
    "        y = label_encoder.fit_transform(x)\n",
    "        temp = y.tolist()\n",
    "        data_set.append(temp)\n",
    "    arr = np.array(data_set)\n",
    "    arr = arr.T\n",
    "    data_set = arr.tolist()\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0, 3, 0], [2, 3, 0], [1, 1, 1], [1, 1, 1], [2, 3, 2]]"
      ]
     },
     "metadata": {},
     "execution_count": 320
    }
   ],
   "source": [
    "data_set = encode_data(training_data)\n",
    "data_set"
   ]
  },
  {
   "source": [
    "## question class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    # a question is used to partition a dataset\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example):\n",
    "        # compare the feature value in an example to the feature\n",
    "        # value in this quesiton\n",
    "        val = example[self.column]\n",
    "        return val >= self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 322
    }
   ],
   "source": [
    "## demo\n",
    "# let's write a question for a numeric question\n",
    "q=Question(1,3)\n",
    "example = data_set[3]\n",
    "q.match(example)  #this will be false since forth example diameter is less than 3"
   ]
  },
  {
   "source": [
    "## partition function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    #partitions dataset, rows: dataset question is used to seperate dataset into two different list\n",
    "    true_rows,false_rows=[],[]\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([[0, 3, 0], [2, 3, 0], [1, 1, 1], [1, 1, 1], [2, 3, 2]], [])"
      ]
     },
     "metadata": {},
     "execution_count": 324
    }
   ],
   "source": [
    "#demonstrate training data whether first categorical value is >=1\n",
    "true_rows, false_rows = partition(data_set, Question(0,0))\n",
    "true_rows, false_rows"
   ]
  },
  {
   "source": [
    "## Gini Impurity\n",
    "\n",
    "Chance of being incorrect if you randomly assign a label to an example in the same set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "# \"\"\" calculate the gini impurity for a list of rows\"\"\"\n",
    "    datasets = np.array(rows)\n",
    "    impurity = 1\n",
    "    if datasets.size == 0:\n",
    "        return 0\n",
    "    #number of labels\n",
    "    unique,counts=np.unique(datasets[:,-1],return_counts=True)\n",
    "    print(datasets[:,-1])\n",
    "    for label,count in zip(unique,counts):\n",
    "        print(label,count)\n",
    "        prob = count / float(np.size(rows,0))\n",
    "        impurity -= prob**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 1 1 2]\n0 2\n1 2\n2 1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6399999999999999"
      ]
     },
     "metadata": {},
     "execution_count": 370
    }
   ],
   "source": [
    "gini(data_set)"
   ]
  },
  {
   "source": [
    "demo, a dataset with no mixing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 327
    }
   ],
   "source": [
    "no_mixing = [['Apple'],\n",
    "              ['Apple']]\n",
    "# this will return 0\n",
    "gini(no_mixing)"
   ]
  },
  {
   "source": [
    "demo, a dataset with many different labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7999999999999998"
      ]
     },
     "metadata": {},
     "execution_count": 328
    }
   ],
   "source": [
    "lots_of_mixing = [['Apple'],\n",
    "                  ['Orange'],\n",
    "                  ['Grape'],\n",
    "                  ['Grapefruit'],\n",
    "                  ['Blueberry']]\n",
    "gini(lots_of_mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Apple' 'Grape' 'Grape' 'Lemon']\nApple 1\nGrape 2\nLemon 1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "metadata": {},
     "execution_count": 371
    }
   ],
   "source": [
    "lots_of_mixing = [['Apple'],\n",
    "                  ['Grape'],\n",
    "                  ['Grape'],\n",
    "                  ['Lemon']]\n",
    "gini(lots_of_mixing)"
   ]
  },
  {
   "source": [
    "## Information Gains"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_gini_impurity):\n",
    "    #the uncertainty of the starting node, minus the weighted impurity of two child nodes\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_gini_impurity - p * gini(left) - (1-p) * gini(right)"
   ]
  },
  {
   "source": [
    "calculate the uncertainty of training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6399999999999999"
      ]
     },
     "metadata": {},
     "execution_count": 330
    }
   ],
   "source": [
    "current_impurity = gini(data_set)\n",
    "current_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.37333333333333324\n0.37333333333333324\n0.0\n0.0\n0.37333333333333324\n"
     ]
    }
   ],
   "source": [
    "datasets = np.array(data_set)\n",
    "# true_rows,false_rows = partition(data_set, Question(0,0))\n",
    "# info_gain(true_rows,false_rows,current_impurity)\n",
    "# datasets[0,1]\n",
    "for data in datasets[:,1]:\n",
    "    # print(data)\n",
    "    true_rows,false_rows = partition(data_set, Question(1,data))\n",
    "    print(info_gain(true_rows,false_rows,current_impurity))"
   ]
  },
  {
   "source": [
    "## build the tree using recursion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    #find the best question to ask by iterating over every feature/value and calculating the information gain\n",
    "    current_impurity  = gini(rows)\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    n_features = len(rows[0])-1\n",
    "\n",
    "    datasets = np.array(data_set)\n",
    "    for col in range(n_features):\n",
    "        unique,counts=np.unique(datasets[:,col],return_counts=True)\n",
    "        for val,count in zip(unique,counts):\n",
    "            question = Question(col,val)\n",
    "            true_rows,false_rows = partition(rows,question)\n",
    "            gain = info_gain(true_rows, false_rows, current_impurity)\n",
    "            # print(col, val, gain)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.37333333333333324"
      ]
     },
     "metadata": {},
     "execution_count": 333
    }
   ],
   "source": [
    "best_gain, best_question = find_best_split(data_set)\n",
    "best_gain"
   ]
  },
  {
   "source": [
    "## build tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, rows):\n",
    "        self.datasets = np.array(rows)\n",
    "        self.unique, self.counts = np.unique(self.datasets[:,-1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self,question,true_branch,false_branch):  \n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    gain, question = find_best_split(rows)\n",
    "\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(\"leaf\")\n",
    "        print((node.unique,node.counts))\n",
    "        return\n",
    "    \n",
    "    print(\"question is: \")\n",
    "    print(node.question.column, node.question.value)\n",
    "\n",
    "    print ('--> True:')\n",
    "    print_tree(node.true_branch)\n",
    "\n",
    "    print ('--> false:')\n",
    "    print_tree(node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "question is: \n1 3\n--> True:\nquestion is: \n0 2\n--> True:\nleaf\n(array([0, 2]), array([1, 1]))\n--> false:\nleaf\n(array([0]), array([1]))\n--> false:\nleaf\n(array([1]), array([2]))\n"
     ]
    }
   ],
   "source": [
    "test = build_tree(data_set)\n",
    "print_tree(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.unique, node.counts\n",
    "\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0]), array([1]))"
      ]
     },
     "metadata": {},
     "execution_count": 340
    }
   ],
   "source": [
    "classify(data_set[0],test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 4, 'Apple'],\n",
    "    ['Red', 2, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "    ['Red', 2, 'Apple'],\n",
    "    ['Yellow', 4, 'Apple'],\n",
    "    ['Green', 5, 'Grape'],\n",
    "    ['Yellow', 1, 'Grape'],\n",
    "    ['Green', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(training_data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    x_color= [ x[0] for x in training_data]\n",
    "    x_label= [ x[2] for x in training_data]\n",
    "    y_color = label_encoder.fit_transform(x_color)\n",
    "    y_label = label_encoder.fit_transform(x_label)\n",
    "    data_set=[ [col1,col2[1],col3] for (col1,col2,col3) in zip(y_color,training_data,y_label)]\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0, 3, 0],\n",
       " [2, 4, 0],\n",
       " [1, 2, 1],\n",
       " [1, 1, 1],\n",
       " [2, 3, 2],\n",
       " [1, 2, 0],\n",
       " [2, 4, 0],\n",
       " [0, 5, 1],\n",
       " [2, 1, 1],\n",
       " [0, 3, 2]]"
      ]
     },
     "metadata": {},
     "execution_count": 343
    }
   ],
   "source": [
    "test_data = encode_data(testing_data)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 (array([0]), array([1]))\n0 (array([0, 2]), array([1, 1]))\n1 (array([1]), array([2]))\n1 (array([1]), array([2]))\n2 (array([0, 2]), array([1, 1]))\n0 (array([1]), array([2]))\n0 (array([0, 2]), array([1, 1]))\n1 (array([0]), array([1]))\n1 (array([1]), array([2]))\n2 (array([0]), array([1]))\n"
     ]
    }
   ],
   "source": [
    "for row in test_data:\n",
    "    print(row[-1],classify(row, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 3,\n",
       " 'Braund, Mr. Owen Harris',\n",
       " 'male',\n",
       " 22.0,\n",
       " 1,\n",
       " 0,\n",
       " 'A/5 21171',\n",
       " 7.25,\n",
       " nan,\n",
       " 'S']"
      ]
     },
     "metadata": {},
     "execution_count": 366
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# train.head()\n",
    "train_data = train.values.tolist()\n",
    "train_data[0]\n",
    "# train_data[0][0]"
   ]
  }
 ]
}